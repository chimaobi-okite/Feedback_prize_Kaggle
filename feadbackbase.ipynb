{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Feedback Prize Competition","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-11T12:22:44.209705Z","iopub.execute_input":"2022-09-11T12:22:44.210738Z","iopub.status.idle":"2022-09-11T12:22:44.235134Z","shell.execute_reply.started":"2022-09-11T12:22:44.210647Z","shell.execute_reply":"2022-09-11T12:22:44.233842Z"}}},{"cell_type":"markdown","source":"## Setup","metadata":{}},{"cell_type":"code","source":"## install the necessary libbraries\n# !pip install -qq transformers\n# !pip install -qq datasets\n# !pip install -qq torch","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:06:20.752807Z","iopub.execute_input":"2022-09-16T09:06:20.753783Z","iopub.status.idle":"2022-09-16T09:06:20.773863Z","shell.execute_reply.started":"2022-09-16T09:06:20.753675Z","shell.execute_reply":"2022-09-16T09:06:20.773019Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"%config Completer.use_jedi = False","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:06:20.933718Z","iopub.execute_input":"2022-09-16T09:06:20.934082Z","iopub.status.idle":"2022-09-16T09:06:20.951984Z","shell.execute_reply.started":"2022-09-16T09:06:20.934049Z","shell.execute_reply":"2022-09-16T09:06:20.950975Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Load Data","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:06:20.954201Z","iopub.execute_input":"2022-09-16T09:06:20.955542Z","iopub.status.idle":"2022-09-16T09:06:21.841723Z","shell.execute_reply.started":"2022-09-16T09:06:20.955504Z","shell.execute_reply":"2022-09-16T09:06:21.840713Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/feedback-prize-english-language-learning/sample_submission.csv\n/kaggle/input/feedback-prize-english-language-learning/train.csv\n/kaggle/input/feedback-prize-english-language-learning/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"train = pd.read_csv('../input/feedback-prize-english-language-learning/train.csv')\ntest = pd.read_csv('../input/feedback-prize-english-language-learning/test.csv')\nss = pd.read_csv('../input/feedback-prize-english-language-learning/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:06:21.843228Z","iopub.execute_input":"2022-09-16T09:06:21.843822Z","iopub.status.idle":"2022-09-16T09:06:22.072718Z","shell.execute_reply.started":"2022-09-16T09:06:21.843784Z","shell.execute_reply":"2022-09-16T09:06:22.071740Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:06:22.074806Z","iopub.execute_input":"2022-09-16T09:06:22.075085Z","iopub.status.idle":"2022-09-16T09:06:22.099130Z","shell.execute_reply.started":"2022-09-16T09:06:22.075060Z","shell.execute_reply":"2022-09-16T09:06:22.098179Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"        text_id                                          full_text  cohesion  \\\n0  0016926B079C  I think that students would benefit from learn...       3.5   \n1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n3  003885A45F42  The best time in life is when you become yours...       4.5   \n4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n\n   syntax  vocabulary  phraseology  grammar  conventions  \n0     3.5         3.0          3.0      4.0          3.0  \n1     2.5         3.0          2.0      2.0          2.5  \n2     3.5         3.0          3.0      3.0          2.5  \n3     4.5         4.5          4.5      4.0          5.0  \n4     3.0         3.0          3.0      2.5          2.5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>full_text</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0016926B079C</td>\n      <td>I think that students would benefit from learn...</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0022683E9EA5</td>\n      <td>When a problem is a change you have to let it ...</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00299B378633</td>\n      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>003885A45F42</td>\n      <td>The best time in life is when you become yours...</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0049B1DF5CCC</td>\n      <td>Small act of kindness can impact in other peop...</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>2.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## EDA","metadata":{}},{"cell_type":"code","source":"# create a copy of train data for eda\ntrain_eda = train.copy()","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:06:29.333408Z","iopub.execute_input":"2022-09-16T09:06:29.334312Z","iopub.status.idle":"2022-09-16T09:06:29.340177Z","shell.execute_reply.started":"2022-09-16T09:06:29.334279Z","shell.execute_reply":"2022-09-16T09:06:29.338943Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# inspect the shape of the data files\nprint(f'The train set has a shape of {train_eda.shape}\\nTest set has a shape of {test.shape}')","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:06:29.931435Z","iopub.execute_input":"2022-09-16T09:06:29.932352Z","iopub.status.idle":"2022-09-16T09:06:29.940597Z","shell.execute_reply.started":"2022-09-16T09:06:29.932316Z","shell.execute_reply":"2022-09-16T09:06:29.939365Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"The train set has a shape of (3911, 8)\nTest set has a shape of (3, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"# inspect data types and missing values\ntrain_eda.info()","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:06:30.471261Z","iopub.execute_input":"2022-09-16T09:06:30.471636Z","iopub.status.idle":"2022-09-16T09:06:30.496538Z","shell.execute_reply.started":"2022-09-16T09:06:30.471603Z","shell.execute_reply":"2022-09-16T09:06:30.495543Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 3911 entries, 0 to 3910\nData columns (total 8 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   text_id      3911 non-null   object \n 1   full_text    3911 non-null   object \n 2   cohesion     3911 non-null   float64\n 3   syntax       3911 non-null   float64\n 4   vocabulary   3911 non-null   float64\n 5   phraseology  3911 non-null   float64\n 6   grammar      3911 non-null   float64\n 7   conventions  3911 non-null   float64\ndtypes: float64(6), object(2)\nmemory usage: 244.6+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"# check for duplicates\ntrain_eda.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:06:31.050264Z","iopub.execute_input":"2022-09-16T09:06:31.050942Z","iopub.status.idle":"2022-09-16T09:06:31.080744Z","shell.execute_reply.started":"2022-09-16T09:06:31.050906Z","shell.execute_reply":"2022-09-16T09:06:31.079551Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"#  data types descriptions\ntrain_eda.describe()","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:06:31.541975Z","iopub.execute_input":"2022-09-16T09:06:31.542326Z","iopub.status.idle":"2022-09-16T09:06:31.575783Z","shell.execute_reply.started":"2022-09-16T09:06:31.542295Z","shell.execute_reply":"2022-09-16T09:06:31.574909Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"          cohesion       syntax   vocabulary  phraseology      grammar  \\\ncount  3911.000000  3911.000000  3911.000000  3911.000000  3911.000000   \nmean      3.127077     3.028254     3.235745     3.116850     3.032856   \nstd       0.662542     0.644399     0.583148     0.655997     0.699841   \nmin       1.000000     1.000000     1.000000     1.000000     1.000000   \n25%       2.500000     2.500000     3.000000     2.500000     2.500000   \n50%       3.000000     3.000000     3.000000     3.000000     3.000000   \n75%       3.500000     3.500000     3.500000     3.500000     3.500000   \nmax       5.000000     5.000000     5.000000     5.000000     5.000000   \n\n       conventions  \ncount  3911.000000  \nmean      3.081053  \nstd       0.671450  \nmin       1.000000  \n25%       2.500000  \n50%       3.000000  \n75%       3.500000  \nmax       5.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3911.000000</td>\n      <td>3911.000000</td>\n      <td>3911.000000</td>\n      <td>3911.000000</td>\n      <td>3911.000000</td>\n      <td>3911.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.127077</td>\n      <td>3.028254</td>\n      <td>3.235745</td>\n      <td>3.116850</td>\n      <td>3.032856</td>\n      <td>3.081053</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.662542</td>\n      <td>0.644399</td>\n      <td>0.583148</td>\n      <td>0.655997</td>\n      <td>0.699841</td>\n      <td>0.671450</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.500000</td>\n      <td>2.500000</td>\n      <td>3.000000</td>\n      <td>2.500000</td>\n      <td>2.500000</td>\n      <td>2.500000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.500000</td>\n      <td>3.500000</td>\n      <td>3.500000</td>\n      <td>3.500000</td>\n      <td>3.500000</td>\n      <td>3.500000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# target value distributions\nplt.figure(figsize = (10,10))\ntrain_eda.hist()\nplt.title('Target Distributions in Train Data')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:06:32.062467Z","iopub.execute_input":"2022-09-16T09:06:32.063175Z","iopub.status.idle":"2022-09-16T09:06:32.634283Z","shell.execute_reply.started":"2022-09-16T09:06:32.063139Z","shell.execute_reply":"2022-09-16T09:06:32.632012Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 720x720 with 0 Axes>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 6 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"# correlation()\ntrain_eda.corr()","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:06:32.650966Z","iopub.execute_input":"2022-09-16T09:06:32.652973Z","iopub.status.idle":"2022-09-16T09:06:32.679911Z","shell.execute_reply.started":"2022-09-16T09:06:32.652932Z","shell.execute_reply":"2022-09-16T09:06:32.678706Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"             cohesion    syntax  vocabulary  phraseology   grammar  \\\ncohesion     1.000000  0.695459    0.666151     0.690058  0.638689   \nsyntax       0.695459  1.000000    0.680562     0.725467  0.709525   \nvocabulary   0.666151  0.680562    1.000000     0.735261  0.654852   \nphraseology  0.690058  0.725467    0.735261     1.000000  0.719746   \ngrammar      0.638689  0.709525    0.654852     0.719746  1.000000   \nconventions  0.666151  0.700025    0.664292     0.666842  0.673301   \n\n             conventions  \ncohesion        0.666151  \nsyntax          0.700025  \nvocabulary      0.664292  \nphraseology     0.666842  \ngrammar         0.673301  \nconventions     1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>cohesion</th>\n      <td>1.000000</td>\n      <td>0.695459</td>\n      <td>0.666151</td>\n      <td>0.690058</td>\n      <td>0.638689</td>\n      <td>0.666151</td>\n    </tr>\n    <tr>\n      <th>syntax</th>\n      <td>0.695459</td>\n      <td>1.000000</td>\n      <td>0.680562</td>\n      <td>0.725467</td>\n      <td>0.709525</td>\n      <td>0.700025</td>\n    </tr>\n    <tr>\n      <th>vocabulary</th>\n      <td>0.666151</td>\n      <td>0.680562</td>\n      <td>1.000000</td>\n      <td>0.735261</td>\n      <td>0.654852</td>\n      <td>0.664292</td>\n    </tr>\n    <tr>\n      <th>phraseology</th>\n      <td>0.690058</td>\n      <td>0.725467</td>\n      <td>0.735261</td>\n      <td>1.000000</td>\n      <td>0.719746</td>\n      <td>0.666842</td>\n    </tr>\n    <tr>\n      <th>grammar</th>\n      <td>0.638689</td>\n      <td>0.709525</td>\n      <td>0.654852</td>\n      <td>0.719746</td>\n      <td>1.000000</td>\n      <td>0.673301</td>\n    </tr>\n    <tr>\n      <th>conventions</th>\n      <td>0.666151</td>\n      <td>0.700025</td>\n      <td>0.664292</td>\n      <td>0.666842</td>\n      <td>0.673301</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# word distribution in train data\ntrain_eda['word_count'] = train_eda['full_text'].map(lambda x: len(x))\ntrain_eda.head()","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:06:34.411879Z","iopub.execute_input":"2022-09-16T09:06:34.412230Z","iopub.status.idle":"2022-09-16T09:06:34.431054Z","shell.execute_reply.started":"2022-09-16T09:06:34.412201Z","shell.execute_reply":"2022-09-16T09:06:34.429881Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"        text_id                                          full_text  cohesion  \\\n0  0016926B079C  I think that students would benefit from learn...       3.5   \n1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n3  003885A45F42  The best time in life is when you become yours...       4.5   \n4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n\n   syntax  vocabulary  phraseology  grammar  conventions  word_count  \n0     3.5         3.0          3.0      4.0          3.0        1387  \n1     2.5         3.0          2.0      2.0          2.5        2635  \n2     3.5         3.0          3.0      3.0          2.5        1663  \n3     4.5         4.5          4.5      4.0          5.0        3973  \n4     3.0         3.0          3.0      2.5          2.5        1326  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>full_text</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n      <th>word_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0016926B079C</td>\n      <td>I think that students would benefit from learn...</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>1387</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0022683E9EA5</td>\n      <td>When a problem is a change you have to let it ...</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>2635</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00299B378633</td>\n      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>1663</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>003885A45F42</td>\n      <td>The best time in life is when you become yours...</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>3973</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0049B1DF5CCC</td>\n      <td>Small act of kindness can impact in other peop...</td>\n      <td>2.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>1326</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# see word count distribution\nsns.histplot(data = train_eda,x = 'word_count',)\nplt.title('Word count Distribution in train set')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:06:35.762046Z","iopub.execute_input":"2022-09-16T09:06:35.762419Z","iopub.status.idle":"2022-09-16T09:06:36.109031Z","shell.execute_reply.started":"2022-09-16T09:06:35.762387Z","shell.execute_reply":"2022-09-16T09:06:36.107754Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"print(f'The least word essay in train set has {train_eda.word_count.min()} words\\nwhile the maximum word essay has {train_eda.word_count.max()} words')","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:06:36.252572Z","iopub.execute_input":"2022-09-16T09:06:36.252973Z","iopub.status.idle":"2022-09-16T09:06:36.259855Z","shell.execute_reply.started":"2022-09-16T09:06:36.252939Z","shell.execute_reply":"2022-09-16T09:06:36.258614Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"The least word essay in train set has 82 words\nwhile the maximum word essay has 6044 words\n","output_type":"stream"}]},{"cell_type":"code","source":"# check corr again\ntrain_eda.corr()","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:06:36.841529Z","iopub.execute_input":"2022-09-16T09:06:36.842452Z","iopub.status.idle":"2022-09-16T09:06:36.865443Z","shell.execute_reply.started":"2022-09-16T09:06:36.842415Z","shell.execute_reply":"2022-09-16T09:06:36.864259Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"             cohesion    syntax  vocabulary  phraseology   grammar  \\\ncohesion     1.000000  0.695459    0.666151     0.690058  0.638689   \nsyntax       0.695459  1.000000    0.680562     0.725467  0.709525   \nvocabulary   0.666151  0.680562    1.000000     0.735261  0.654852   \nphraseology  0.690058  0.725467    0.735261     1.000000  0.719746   \ngrammar      0.638689  0.709525    0.654852     0.719746  1.000000   \nconventions  0.666151  0.700025    0.664292     0.666842  0.673301   \nword_count   0.236373  0.205633    0.281801     0.224301  0.089115   \n\n             conventions  word_count  \ncohesion        0.666151    0.236373  \nsyntax          0.700025    0.205633  \nvocabulary      0.664292    0.281801  \nphraseology     0.666842    0.224301  \ngrammar         0.673301    0.089115  \nconventions     1.000000    0.161360  \nword_count      0.161360    1.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n      <th>word_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>cohesion</th>\n      <td>1.000000</td>\n      <td>0.695459</td>\n      <td>0.666151</td>\n      <td>0.690058</td>\n      <td>0.638689</td>\n      <td>0.666151</td>\n      <td>0.236373</td>\n    </tr>\n    <tr>\n      <th>syntax</th>\n      <td>0.695459</td>\n      <td>1.000000</td>\n      <td>0.680562</td>\n      <td>0.725467</td>\n      <td>0.709525</td>\n      <td>0.700025</td>\n      <td>0.205633</td>\n    </tr>\n    <tr>\n      <th>vocabulary</th>\n      <td>0.666151</td>\n      <td>0.680562</td>\n      <td>1.000000</td>\n      <td>0.735261</td>\n      <td>0.654852</td>\n      <td>0.664292</td>\n      <td>0.281801</td>\n    </tr>\n    <tr>\n      <th>phraseology</th>\n      <td>0.690058</td>\n      <td>0.725467</td>\n      <td>0.735261</td>\n      <td>1.000000</td>\n      <td>0.719746</td>\n      <td>0.666842</td>\n      <td>0.224301</td>\n    </tr>\n    <tr>\n      <th>grammar</th>\n      <td>0.638689</td>\n      <td>0.709525</td>\n      <td>0.654852</td>\n      <td>0.719746</td>\n      <td>1.000000</td>\n      <td>0.673301</td>\n      <td>0.089115</td>\n    </tr>\n    <tr>\n      <th>conventions</th>\n      <td>0.666151</td>\n      <td>0.700025</td>\n      <td>0.664292</td>\n      <td>0.666842</td>\n      <td>0.673301</td>\n      <td>1.000000</td>\n      <td>0.161360</td>\n    </tr>\n    <tr>\n      <th>word_count</th>\n      <td>0.236373</td>\n      <td>0.205633</td>\n      <td>0.281801</td>\n      <td>0.224301</td>\n      <td>0.089115</td>\n      <td>0.161360</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Insights from eda\n\n* The target columns are strongly correlated with each other so it will be best to use a multi-output regression model instead predicting individually\n* The essay lengths spans from 82 to 6044 words with the most within 1000-3000 word range\n* There is little correlation between word length and target variables","metadata":{}},{"cell_type":"markdown","source":"## Data Preprocessing and Modelling\n\nThe data processing and modelling approaches will be based on using a transformer ","metadata":{}},{"cell_type":"code","source":"#  import the necessaray libraries\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers import Trainer, TrainingArguments\nfrom datasets import Dataset\n\nfrom transformers.models.bert.modeling_bert import BertModel\nfrom transformers.models.bert.modeling_bert import BertPreTrainedModel\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch\n\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nimport gc","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:06:39.231451Z","iopub.execute_input":"2022-09-16T09:06:39.233832Z","iopub.status.idle":"2022-09-16T09:06:47.307864Z","shell.execute_reply.started":"2022-09-16T09:06:39.233769Z","shell.execute_reply":"2022-09-16T09:06:47.306695Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model_ckpt =  'bert-base-uncased'\nsave_dir = './outputs/'\nN_FOLDS = 5\nN_LABELS = 6\nMAX_LENGHT = 512","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:06:47.313917Z","iopub.execute_input":"2022-09-16T09:06:47.317100Z","iopub.status.idle":"2022-09-16T09:06:47.324095Z","shell.execute_reply.started":"2022-09-16T09:06:47.317058Z","shell.execute_reply":"2022-09-16T09:06:47.323065Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\nconfig = AutoConfig.from_pretrained(model_ckpt)\nbase_model = AutoModel.from_pretrained(model_ckpt)","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:06:47.329626Z","iopub.execute_input":"2022-09-16T09:06:47.332540Z","iopub.status.idle":"2022-09-16T09:07:14.138453Z","shell.execute_reply.started":"2022-09-16T09:06:47.332493Z","shell.execute_reply":"2022-09-16T09:07:14.137045Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83098a75f58c4ff8a993d8d3c66689f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c49a7d467fe74a1c849e6d5400f669a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d4a158753e74db98339299d229c03ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8a5ea0542564882b8c292cfb31d0771"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3061ad37afb24c789000ed9eaa5349c6"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"# save to disk for inference\ntokenizer.save_pretrained(f'{save_dir}tokenizer.h5')\nconfig.save_pretrained(f'{save_dir}config.h5')","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:07:14.141207Z","iopub.execute_input":"2022-09-16T09:07:14.142000Z","iopub.status.idle":"2022-09-16T09:07:14.212753Z","shell.execute_reply.started":"2022-09-16T09:07:14.141953Z","shell.execute_reply":"2022-09-16T09:07:14.211920Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# tokenize data\ndef tokenize_and_process(examples):\n    text = examples['full_text']\n#     seq_len = len(text)\n#     seq_len = text_len if (text_len > tokenizer.model_max_length)  else tokenizer.model_max_length\n    tokens = tokenizer(text, padding='max_length', max_length= MAX_LENGHT, truncation= True)\n    if len(examples)> 3: # example comes from train ds\n        tokens['labels'] = [examples[col] for col in target_cols]\n#     tokens['seq_len'] = seq_len\n    return tokens","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:07:14.214171Z","iopub.execute_input":"2022-09-16T09:07:14.214794Z","iopub.status.idle":"2022-09-16T09:07:14.712312Z","shell.execute_reply.started":"2022-09-16T09:07:14.214756Z","shell.execute_reply":"2022-09-16T09:07:14.710728Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"target_cols = [col for col in list(train.columns)[2:]]\nkeep_cols = ['input_ids', 'attention_mask', 'labels'] # 'seq_len'\ndrop_cols = [col for col in train.columns if col not in keep_cols]","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:08:35.571571Z","iopub.execute_input":"2022-09-16T09:08:35.572728Z","iopub.status.idle":"2022-09-16T09:08:35.578379Z","shell.execute_reply.started":"2022-09-16T09:08:35.572678Z","shell.execute_reply":"2022-09-16T09:08:35.577247Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# use Kfold validation\nkf = KFold(n_splits=5, shuffle= True, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:09:11.263359Z","iopub.execute_input":"2022-09-16T09:09:11.264086Z","iopub.status.idle":"2022-09-16T09:09:11.269612Z","shell.execute_reply.started":"2022-09-16T09:09:11.264047Z","shell.execute_reply":"2022-09-16T09:09:11.268423Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def prepare_ds(train_df, val_df):\n    '''Function converts train and validation dataframe to form required for modelling'''\n    train_ds =  Dataset.from_pandas(train_df,preserve_index = False)\n    val_ds = Dataset.from_pandas(val_df, preserve_index = False)\n    train_ds = train_ds.map(tokenize_and_process)\n    val_ds = val_ds.map(tokenize_and_process)\n    encoded_train = train_ds.remove_columns(drop_cols)\n    encoded_val = val_ds.remove_columns(drop_cols)\n    encoded_train.set_format('torch')\n    encoded_val.set_format('torch')\n    return encoded_train, encoded_val","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:09:12.062513Z","iopub.execute_input":"2022-09-16T09:09:12.063544Z","iopub.status.idle":"2022-09-16T09:09:12.070814Z","shell.execute_reply.started":"2022-09-16T09:09:12.063470Z","shell.execute_reply":"2022-09-16T09:09:12.069776Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"class MeanPooling(nn.Module):\n    def __init__(self):\n        super(MeanPooling, self).__init__()\n        \n    def forward(self, last_hidden_state, attention_mask):\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        mean_embeddings = sum_embeddings / sum_mask\n        return mean_embeddings\n\nclass FeedBackModel(BertPreTrainedModel):\n    \n    def __init__(self, config):\n        super().__init__(config)\n        num_labels = config.num_labels\n        self.bert =  BertModel(config)\n        self.pool = MeanPooling()\n#         self.drop = nn.Dropout(0.1)\n        self.fc1 = nn.Linear(768, num_labels)\n        self.embed = nn.Embedding(embedding_dim=768, num_embeddings=7000)\n        \n        self.init_weights()\n#         self.bert.requires_grad_()\n        \n    def forward(self, input_ids = None, attention_mask = None, labels = None):\n#         embed = self.embed(seq_len)\n        z = self.bert(input_ids = input_ids, attention_mask = attention_mask)['last_hidden_state']\n        outs = self.pool(z, attention_mask)\n#         outs = outs + embed\n        outs = self.fc1(outs)\n        if labels != None:\n            loss_fn = nn.MSELoss(reduction='mean')\n            loss = loss_fn(outs, labels)\n            return {'logits' : outs , 'loss' : loss}\n        return {'logits' : outs}","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:09:14.853850Z","iopub.execute_input":"2022-09-16T09:09:14.856450Z","iopub.status.idle":"2022-09-16T09:09:14.886868Z","shell.execute_reply.started":"2022-09-16T09:09:14.856410Z","shell.execute_reply":"2022-09-16T09:09:14.885777Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"config.num_labels = N_LABELS # add number of labels to model configuration file\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # initialize device","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:09:18.701699Z","iopub.execute_input":"2022-09-16T09:09:18.702382Z","iopub.status.idle":"2022-09-16T09:09:18.767778Z","shell.execute_reply.started":"2022-09-16T09:09:18.702346Z","shell.execute_reply":"2022-09-16T09:09:18.766557Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# custom trainer specifies the way to calculate loss for our model\nclass CustomTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False):\n        labels = inputs.get(\"labels\")\n        # forward pass\n        outputs = model(**inputs)\n        logits = outputs.get(\"logits\")\n        # compute custom loss (suppose one has 3 labels with different weights)\n        loss_fct = nn.MSELoss(reduction='mean')\n        loss = loss_fct(logits, labels)\n        return (loss, outputs) if return_outputs else loss","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:09:20.288154Z","iopub.execute_input":"2022-09-16T09:09:20.288757Z","iopub.status.idle":"2022-09-16T09:09:20.295044Z","shell.execute_reply.started":"2022-09-16T09:09:20.288720Z","shell.execute_reply":"2022-09-16T09:09:20.293791Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(pred):\n    '''Using competition metrics'''\n    labels = pred.label_ids\n    preds = pred.predictions\n    mse = np.mean(np.square(labels- preds), axis = 0)\n    rmse = np.sqrt(mse)\n    mcrmse = np.mean(rmse, axis = 0)\n    return {\"mcrmse\":  mcrmse}","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:09:21.122999Z","iopub.execute_input":"2022-09-16T09:09:21.123365Z","iopub.status.idle":"2022-09-16T09:09:21.129865Z","shell.execute_reply.started":"2022-09-16T09:09:21.123332Z","shell.execute_reply":"2022-09-16T09:09:21.128656Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# define trainging args\nnum_epochs = 4\nbatch_size = 8\nlogging_steps = (len(train)*0.8) // batch_size\nmodel_name = f\"{model_ckpt}-feedback_base\"\ntraining_args = TrainingArguments(output_dir=model_name, log_level=\"error\", num_train_epochs=num_epochs,\n                                  load_best_model_at_end = True,\n                                  save_strategy='epoch',\n                                  per_device_train_batch_size=batch_size,\n                                  fp16 = False,learning_rate = 3e-5,\n                                  per_device_eval_batch_size=batch_size, evaluation_strategy=\"epoch\",\n                                  save_steps=100, weight_decay=0.01, disable_tqdm=False,\n                                  logging_steps=logging_steps, push_to_hub=False,report_to='none')","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:09:21.701879Z","iopub.execute_input":"2022-09-16T09:09:21.702250Z","iopub.status.idle":"2022-09-16T09:09:21.717562Z","shell.execute_reply.started":"2022-09-16T09:09:21.702217Z","shell.execute_reply":"2022-09-16T09:09:21.716407Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def model_init():\n    return (FeedBackModel.from_pretrained(model_ckpt, config = config).to(device))","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:09:23.102458Z","iopub.execute_input":"2022-09-16T09:09:23.103397Z","iopub.status.idle":"2022-09-16T09:09:23.108079Z","shell.execute_reply.started":"2022-09-16T09:09:23.103362Z","shell.execute_reply":"2022-09-16T09:09:23.106937Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# cross validate across different data points\neval_scores = []\n\nfor fold, (train_index, test_index) in enumerate(kf.split(train)):\n    \n    print(f\"====== FOLD RUNNING {fold + 1}======\")\n    \n    train_k , val_k = train.iloc[train_index, :], train.iloc[test_index,:]\n    train_ds, val_ds = prepare_ds(train_k, val_k)\n    \n    trainer = CustomTrainer(model_init= model_init, args=training_args,\n                       compute_metrics=compute_metrics,\n                       train_dataset=train_ds,\n                       eval_dataset=val_ds,\n                       tokenizer=tokenizer)\n    \n    trainer.train()\n    \n    score = trainer.evaluate(val_ds)['eval_mcrmse']\n    \n    trainer.model.save_pretrained(f'{save_dir}bert_model{fold + 1}.h5') # save best model for each step\n    eval_scores.append(score)\n    \n    print(f'Evaluation scores after {fold + 1} folds -->{eval_scores}')\n    \n    del train_ds, val_ds, train_k, val_k\n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-09-16T09:09:25.062105Z","iopub.execute_input":"2022-09-16T09:09:25.062467Z","iopub.status.idle":"2022-09-16T10:16:05.681234Z","shell.execute_reply.started":"2022-09-16T09:09:25.062436Z","shell.execute_reply":"2022-09-16T10:16:05.680152Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"====== FOLD RUNNING 1======\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3128 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d31cb818315441ebac039747e22272a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/783 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4452082ed64d45de94523e07f84e14e4"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1564' max='1564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1564/1564 12:44, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mcrmse</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.418900</td>\n      <td>0.292006</td>\n      <td>0.538375</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.230500</td>\n      <td>0.248008</td>\n      <td>0.496858</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.180000</td>\n      <td>0.260510</td>\n      <td>0.509061</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.145100</td>\n      <td>0.272046</td>\n      <td>0.520813</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [98/98 00:14]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation scores after 1 folds -->[0.4968580901622772]\n====== FOLD RUNNING 2======\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3129 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca6ec9973dde4d7883f1b3f9540f826e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/782 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fdeaeb0b3984761aee7638f0b86c79c"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1568' max='1568' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1568/1568 12:44, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mcrmse</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.424800</td>\n      <td>0.324861</td>\n      <td>0.566972</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.229200</td>\n      <td>0.399357</td>\n      <td>0.629185</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.175300</td>\n      <td>0.259616</td>\n      <td>0.508416</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.140900</td>\n      <td>0.283818</td>\n      <td>0.531102</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [98/98 00:14]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation scores after 2 folds -->[0.4968580901622772, 0.5084158778190613]\n====== FOLD RUNNING 3======\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3129 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"394f2cc8551347e294a4169add5a7927"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/782 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b4c94d8adc5460aa1464abe5be08f49"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1568' max='1568' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1568/1568 12:48, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mcrmse</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.447900</td>\n      <td>0.270803</td>\n      <td>0.519860</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.234700</td>\n      <td>0.234522</td>\n      <td>0.483694</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.182000</td>\n      <td>0.376077</td>\n      <td>0.610194</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.146200</td>\n      <td>0.287394</td>\n      <td>0.534712</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [98/98 00:14]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation scores after 3 folds -->[0.4968580901622772, 0.5084158778190613, 0.4836938679218292]\n====== FOLD RUNNING 4======\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3129 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e78f15e8f6b54049ae106e55af0e1045"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/782 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70b335df829c4cfcbd455ea609454ca5"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1568' max='1568' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1568/1568 12:48, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mcrmse</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.408800</td>\n      <td>0.345082</td>\n      <td>0.583605</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.227900</td>\n      <td>0.271418</td>\n      <td>0.520344</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.176300</td>\n      <td>0.256819</td>\n      <td>0.505569</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.141700</td>\n      <td>0.275923</td>\n      <td>0.524309</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [98/98 00:14]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation scores after 4 folds -->[0.4968580901622772, 0.5084158778190613, 0.4836938679218292, 0.505569338798523]\n====== FOLD RUNNING 5======\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3129 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69fa93be823040e5a589a0774fdd82b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/782 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b201b737de73468c8700d99217ed9235"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1568' max='1568' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1568/1568 12:48, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Mcrmse</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.420300</td>\n      <td>0.277792</td>\n      <td>0.524696</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.227600</td>\n      <td>0.297347</td>\n      <td>0.541690</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.178300</td>\n      <td>0.275594</td>\n      <td>0.522837</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.141800</td>\n      <td>0.277852</td>\n      <td>0.524644</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='98' max='98' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [98/98 00:14]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation scores after 5 folds -->[0.4968580901622772, 0.5084158778190613, 0.4836938679218292, 0.505569338798523, 0.5228366255760193]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Making Prediction On Test Set","metadata":{}},{"cell_type":"code","source":"def prepare_test_ds(test_df):\n    '''\n    Function converts test dataframe to pytorch tensor for modelling\n    \n    inputs:\n        test_df : pd.DataFrame\n        \n    outputs:\n        encoded_test : Dataset\n        test_ds : Dataset - used to extract test_ids\n    \n    '''\n    test_ds = Dataset.from_pandas(test_df)\n    tokenized_test = test_ds.map(tokenize_and_process)\n    encoded_test =  tokenized_test.remove_columns(['full_text'])\n    encoded_test.set_format('torch')\n    return test_ds, encoded_test","metadata":{"execution":{"iopub.status.busy":"2022-09-16T10:17:28.005174Z","iopub.execute_input":"2022-09-16T10:17:28.005557Z","iopub.status.idle":"2022-09-16T10:17:28.012079Z","shell.execute_reply.started":"2022-09-16T10:17:28.005525Z","shell.execute_reply":"2022-09-16T10:17:28.011038Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"test_ds, encode_test = prepare_test_ds(test)\n\n# initialize datasets for trainer , wont be used\ntrain_df, val_df = train_test_split(train, test_size = 0.2, random_state = 42)\nencoded_train, encoded_val =  prepare_ds(train_df, val_df)\n\neval_tokenizer = AutoTokenizer.from_pretrained(f'{save_dir}tokenizer.h5') # used saved tokenizer","metadata":{"execution":{"iopub.status.busy":"2022-09-16T10:17:37.374283Z","iopub.execute_input":"2022-09-16T10:17:37.374656Z","iopub.status.idle":"2022-09-16T10:17:45.540136Z","shell.execute_reply.started":"2022-09-16T10:17:37.374624Z","shell.execute_reply":"2022-09-16T10:17:45.539227Z"},"trusted":true},"execution_count":35,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f79964b82bf0485a93f1899b7b0c0ac0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3128 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb447304e3d14000ae3aedf322e940c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/783 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a669beec7e84996855ff1aed2836b0d"}},"metadata":{}}]},{"cell_type":"code","source":"for fold in range(5):\n    \n    print(f\"====== FOLD RUNNING {fold}======\")\n    \n    model = FeedBackModel.from_pretrained(f'{save_dir}bert_model{fold + 1}.h5', config = config).eval().to(device)\n    \n    trainer = CustomTrainer(model = model, args=training_args,\n                       compute_metrics=compute_metrics,\n                       train_dataset=encoded_train,\n                       eval_dataset=encoded_val,\n                       tokenizer=tokenizer)\n    \n    preds = trainer.predict(encode_test)[0]\n    \n    if fold == 0:\n        final_preds = preds * (1/5)\n    else:\n        final_preds += preds * (1/5)\n\n    del model\n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-09-16T10:17:54.873583Z","iopub.execute_input":"2022-09-16T10:17:54.873966Z","iopub.status.idle":"2022-09-16T10:18:13.001023Z","shell.execute_reply.started":"2022-09-16T10:17:54.873933Z","shell.execute_reply":"2022-09-16T10:18:13.000025Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"====== FOLD RUNNING 0======\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 : < :]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"====== FOLD RUNNING 1======\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 : < :]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"====== FOLD RUNNING 2======\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 : < :]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"====== FOLD RUNNING 3======\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 : < :]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"====== FOLD RUNNING 4======\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 : < :]\n    </div>\n    "},"metadata":{}}]},{"cell_type":"code","source":"# create submission file\nsub_dict = {}\nsub_dict['text_id'] = test_ds['text_id']\nfor i, col in enumerate(target_cols):\n    sub_dict[col] = final_preds[:, i]\nsub_df = pd.DataFrame(sub_dict)\nsub_df","metadata":{"execution":{"iopub.status.busy":"2022-09-16T10:18:42.119315Z","iopub.execute_input":"2022-09-16T10:18:42.119696Z","iopub.status.idle":"2022-09-16T10:18:42.138052Z","shell.execute_reply.started":"2022-09-16T10:18:42.119662Z","shell.execute_reply":"2022-09-16T10:18:42.136642Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"        text_id  cohesion    syntax  vocabulary  phraseology   grammar  \\\n0  0000C359D63E  2.932452  2.767177    3.050929     2.883127  2.717170   \n1  000BAD50D026  2.694888  2.504544    2.769678     2.491786  2.341357   \n2  00367BB2546B  3.785535  3.685659    3.829267     3.762333  3.700413   \n\n   conventions  \n0     2.771553  \n1     2.728239  \n2     3.857792  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000C359D63E</td>\n      <td>2.932452</td>\n      <td>2.767177</td>\n      <td>3.050929</td>\n      <td>2.883127</td>\n      <td>2.717170</td>\n      <td>2.771553</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000BAD50D026</td>\n      <td>2.694888</td>\n      <td>2.504544</td>\n      <td>2.769678</td>\n      <td>2.491786</td>\n      <td>2.341357</td>\n      <td>2.728239</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00367BB2546B</td>\n      <td>3.785535</td>\n      <td>3.685659</td>\n      <td>3.829267</td>\n      <td>3.762333</td>\n      <td>3.700413</td>\n      <td>3.857792</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sub_df.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2022-09-16T10:18:52.048846Z","iopub.execute_input":"2022-09-16T10:18:52.049207Z","iopub.status.idle":"2022-09-16T10:18:52.060759Z","shell.execute_reply.started":"2022-09-16T10:18:52.049176Z","shell.execute_reply":"2022-09-16T10:18:52.059704Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}